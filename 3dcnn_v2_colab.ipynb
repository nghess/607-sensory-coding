{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOnX6yQAzWWE43ZCc88HokT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nghess/607-sensory-coding/blob/main/Copy_of_3dCNN_v1_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile as tiff\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "E7q4MU6943Kz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl86lWdq3lg4",
        "outputId": "291be758-164d-4934-f505-932deb10dcef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/607_sensory_coding\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Navigate to the repository's directory\n",
        "repo_path = os.path.join(path, '607-sensory-coding')\n",
        "os.chdir(repo_path)"
      ],
      "metadata": {
        "id": "w0XPDO0q4uuU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NqBblxdMJMcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TiffDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
        "        image = tiff.imread(img_name)  # Load stack\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Ensure the image is a float tensor\n",
        "        if not isinstance(image, torch.FloatTensor):\n",
        "            image = image.type(torch.FloatTensor)\n",
        "\n",
        "        # Convert labels to numerical format\n",
        "        rotation_class = 1 if self.annotations.iloc[index, 1] == 'clockwise' else 0\n",
        "        input_class_mapping = {'cross': 0, 'tee': 1, 'elbow': 2, 'radius': 3, 'diameter': 4}\n",
        "        input_class = input_class_mapping[self.annotations.iloc[index, 2]]\n",
        "\n",
        "        # Combine the labels (e.g., using one-hot encoding for the input class)\n",
        "        label = torch.tensor([rotation_class, input_class], dtype=torch.long)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Run transforms. Normalizes image stacks between 0 and 1.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = TiffDataset(csv_file='dataset/scatter/labels_scatter.csv', root_dir='dataset/', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "PQJFLUdP5CsD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Model"
      ],
      "metadata": {
        "id": "v6Nx9f6LJH2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Simple3DCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Simple3DCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 45 * 32, 512)  # Adjust the size\n",
        "        self.fc_rotation = nn.Linear(512, 2)  # Two classes for rotation\n",
        "        self.fc_input = nn.Linear(512, 5)  # Five classes for input type\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        #print(x.shape) #torch.Size([32, 64, 45, 64]) for 256x256 [32, 32, 45, 32]) for 128x128\n",
        "        x = x.view(-1, 32 * 32 * 45 * 32)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        rotation_output = self.fc_rotation(x)\n",
        "        input_output = self.fc_input(x)\n",
        "        return rotation_output, input_output\n",
        "\n",
        "model = Simple3DCNN()"
      ],
      "metadata": {
        "id": "7KNQIvYL5F2d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "9jU428QFJDEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# Initialize a list to keep track of loss values\n",
        "loss_values = []\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is active.\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the device (GPU or CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(dataloader):\n",
        "\n",
        "        # Move to GPU\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Split the labels\n",
        "        rotation_labels = labels[:, 0]\n",
        "        input_labels = labels[:, 1]\n",
        "\n",
        "        # Reset gradient\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Assuming your model's output is designed to handle both types of labels\n",
        "        loss_rotation = criterion(outputs[0], rotation_labels)\n",
        "        loss_input = criterion(outputs[1], input_labels)\n",
        "        loss = loss_rotation + loss_input  # Combine losses, or handle as you see fit\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # At the end of each epoch, store the average loss\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    loss_values.append(epoch_loss)\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsFj5-Gr5I57",
        "outputId": "3c2cfe4e-6800-43cd-9fba-7b65c72d739d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is active.\n",
            "Epoch [1/100], Loss: 2.3362\n",
            "Epoch [2/100], Loss: 2.3229\n",
            "Epoch [3/100], Loss: 2.2806\n",
            "Epoch [4/100], Loss: 2.1236\n",
            "Epoch [5/100], Loss: 1.3884\n",
            "Epoch [6/100], Loss: 1.2566\n",
            "Epoch [7/100], Loss: 1.0779\n",
            "Epoch [8/100], Loss: 0.8261\n",
            "Epoch [9/100], Loss: 0.4619\n",
            "Epoch [10/100], Loss: 1.0847\n",
            "Epoch [11/100], Loss: 0.9883\n",
            "Epoch [12/100], Loss: 0.5957\n",
            "Epoch [13/100], Loss: 0.2838\n",
            "Epoch [14/100], Loss: 0.1377\n",
            "Epoch [15/100], Loss: 0.0841\n",
            "Epoch [16/100], Loss: 0.0389\n",
            "Epoch [17/100], Loss: 0.0074\n",
            "Epoch [18/100], Loss: 0.0017\n",
            "Epoch [19/100], Loss: 0.0010\n",
            "Epoch [20/100], Loss: 0.0008\n",
            "Epoch [21/100], Loss: 0.0007\n",
            "Epoch [22/100], Loss: 0.0006\n",
            "Epoch [23/100], Loss: 0.0005\n",
            "Epoch [24/100], Loss: 0.0004\n",
            "Epoch [25/100], Loss: 0.0004\n",
            "Epoch [26/100], Loss: 0.0004\n",
            "Epoch [27/100], Loss: 0.0003\n",
            "Epoch [28/100], Loss: 0.0003\n",
            "Epoch [29/100], Loss: 0.0003\n",
            "Epoch [30/100], Loss: 0.0003\n",
            "Epoch [31/100], Loss: 0.0002\n",
            "Epoch [32/100], Loss: 0.0002\n",
            "Epoch [33/100], Loss: 0.0002\n",
            "Epoch [34/100], Loss: 0.0002\n",
            "Epoch [35/100], Loss: 0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model to File"
      ],
      "metadata": {
        "id": "TwGTSrcXJxO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(model, '/content/drive/My Drive/607_sensory_coding/test_model_2.pt')"
      ],
      "metadata": {
        "id": "DBAmHUoS77Uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "sjsQE4kTDXKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Model"
      ],
      "metadata": {
        "id": "_RpXvKiMJz7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = TiffDataset(csv_file='dataset/scatter/labels_scatter.csv', root_dir='dataset/', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Zg4mMPeA9KgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test label prediction performance\n",
        "def test_model(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct_rotation, correct_input, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            rotation_labels, input_labels = labels[:, 0], labels[:, 1]\n",
        "\n",
        "            rotation_output, input_output = model(inputs)\n",
        "\n",
        "            _, predicted_rotation = torch.max(rotation_output.data, 1)\n",
        "            _, predicted_input = torch.max(input_output.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct_rotation += (predicted_rotation == rotation_labels).sum().item()\n",
        "            correct_input += (predicted_input == input_labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the network on rotation prediction: {100 * correct_rotation / total}%')\n",
        "    print(f'Accuracy of the network on input type prediction: {100 * correct_input / total}%')\n",
        "\n",
        "test_model(model, test_loader, device)"
      ],
      "metadata": {
        "id": "AoFmssCl5Ndf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Trained Layers"
      ],
      "metadata": {
        "id": "P0ZOW93HWr2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to pull a single sample input out for layer visualization\n",
        "def get_sample_input(data_loader):\n",
        "\n",
        "    for inputs, _ in data_loader:\n",
        "        # Select one instance in the batch\n",
        "        sample_input = inputs[0]\n",
        "        return sample_input\n",
        "\n",
        "sample_input = get_sample_input(test_loader)"
      ],
      "metadata": {
        "id": "W8GUrGWX86pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_maps(model, input_tensor, selected_layers, ncols=6):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Function to get the output of a layer\n",
        "    def get_features_map(layer, input, output):\n",
        "        feature_maps.append(output.cpu().data.numpy())\n",
        "\n",
        "    # Attach hooks to the selected layers\n",
        "    hooks = []\n",
        "    for name, layer in model.named_modules():\n",
        "        if name in selected_layers:\n",
        "            hooks.append(layer.register_forward_hook(get_features_map))\n",
        "\n",
        "    # Initialize the feature maps list and pass the input through the model\n",
        "    feature_maps = []\n",
        "    with torch.no_grad():\n",
        "        model(input_tensor.unsqueeze(0).to(device))\n",
        "\n",
        "    # Remove hooks (important to avoid memory leak)\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # Plotting\n",
        "    for ii in range(32):\n",
        "      for layer_maps in feature_maps:\n",
        "          n_features = layer_maps.shape[1]\n",
        "          nrows = n_features // ncols + int(n_features % ncols != 0)\n",
        "          fig, axes = plt.subplots(nrows, ncols, figsize=(20, 2 * nrows))\n",
        "          for i in range(n_features):\n",
        "              row = i // ncols\n",
        "              col = i % ncols\n",
        "              ax = axes[row, col] if nrows > 1 else axes[col]\n",
        "              ax.imshow(layer_maps[ii, i, :, :], cmap='gray')\n",
        "              ax.axis('off')\n",
        "\n",
        "          #plt.show()\n",
        "\n",
        "          # Save the figure\n",
        "          plt.savefig(f\"epoch_{epochs}_conv2[{ii}].png\")  # Saves the plot as a PNG file\n",
        "          plt.close()  # Closes the current figure\n",
        "\n",
        "# Pull out a layer and plot slices\n",
        "selected_layers = ['conv2']\n",
        "plot_feature_maps(model, sample_input, selected_layers, ncols=6)\n"
      ],
      "metadata": {
        "id": "br1Ww3pz8oLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close('all')"
      ],
      "metadata": {
        "id": "EP7ni4bIri_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataset[0])\n",
        "# fig, axes = plt.subplots(nrows, ncols, figsize=(20, 2 * nrows))\n",
        "\n",
        "ncols = 4\n",
        "nrows = 4\n",
        "fig, axes = plt.subplots(nrows, ncols, figsize=(20, 2 * nrows))\n",
        "\n",
        "# Plot a 4x4 grid of images from dataset\n",
        "for i in range(16):\n",
        "    row = i // ncols\n",
        "    col = i % ncols\n",
        "    ax = axes[row, col] if nrows > 1 else axes[col]\n",
        "    # add correspnding label from labels list\n",
        "    #rotation_labels, input_labels = labels[:, 0], labels[:, 1]\n",
        "    ax.set_title(f\"{rotation_labels[0]}, {input_labels[0]}\")\n",
        "    ax.imshow(dataset[i][0][30], cmap='gray')\n",
        "    ax.axis('off')"
      ],
      "metadata": {
        "id": "IKUU1YZyqdTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}