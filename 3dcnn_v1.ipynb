{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiffDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = tiff.imread(img_name)  # This should read the entire stack\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Ensure the image is a float tensor\n",
    "        if not isinstance(image, torch.FloatTensor):\n",
    "            image = image.type(torch.FloatTensor)\n",
    "\n",
    "        # Convert labels to numerical format\n",
    "        rotation_class = 1 if self.annotations.iloc[index, 1] == 'clockwise' else 0\n",
    "        input_class_mapping = {'cross': 0, 'tee': 1, 'elbow': 2, 'radius': 3, 'diameter': 4}\n",
    "        input_class = input_class_mapping[self.annotations.iloc[index, 2]]\n",
    "\n",
    "        # Combine the labels (e.g., using one-hot encoding for the input class)\n",
    "        label = torch.tensor([rotation_class, input_class], dtype=torch.long)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Example usage\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = TiffDataset(csv_file='dataset/labels.csv', root_dir='dataset/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple3DCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv3d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 64 * 45 * 64, 512)  # Adjust the size\n",
    "        self.fc_rotation = nn.Linear(512, 2)  # Two classes for rotation\n",
    "        self.fc_input = nn.Linear(512, 5)  # Five classes for input type\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #print(x.shape) torch.Size([32, 64, 45, 64])\n",
    "        x = x.view(-1, 32 * 64 * 45 * 64)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        rotation_output = self.fc_rotation(x)\n",
    "        input_output = self.fc_input(x)\n",
    "        return rotation_output, input_output\n",
    "\n",
    "model = Simple3DCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is active.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 11.25 GiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 705.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32ma:\\Git Repos\\607-sensory-coding\\3dcnn_v1.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Git%20Repos/607-sensory-coding/3dcnn_v1.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_rotation \u001b[39m+\u001b[39m loss_input  \u001b[39m# Combine losses, or handle as you see fit\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Git%20Repos/607-sensory-coding/3dcnn_v1.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/a%3A/Git%20Repos/607-sensory-coding/3dcnn_v1.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Git%20Repos/607-sensory-coding/3dcnn_v1.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/a%3A/Git%20Repos/607-sensory-coding/3dcnn_v1.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# At the end of each epoch, store the average loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hssla\\miniconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hssla\\miniconda3\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\hssla\\miniconda3\\Lib\\site-packages\\torch\\optim\\sgd.py:75\u001b[0m, in \u001b[0;36mSGD.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     71\u001b[0m momentum_buffer_list \u001b[39m=\u001b[39m []\n\u001b[0;32m     73\u001b[0m has_sparse_grad \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001b[1;32m---> 75\u001b[0m sgd(params_with_grad,\n\u001b[0;32m     76\u001b[0m     d_p_list,\n\u001b[0;32m     77\u001b[0m     momentum_buffer_list,\n\u001b[0;32m     78\u001b[0m     weight_decay\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     79\u001b[0m     momentum\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mmomentum\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     80\u001b[0m     lr\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     81\u001b[0m     dampening\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mdampening\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     82\u001b[0m     nesterov\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mnesterov\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     83\u001b[0m     maximize\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     84\u001b[0m     has_sparse_grad\u001b[39m=\u001b[39mhas_sparse_grad,\n\u001b[0;32m     85\u001b[0m     foreach\u001b[39m=\u001b[39mgroup[\u001b[39m'\u001b[39m\u001b[39mforeach\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     87\u001b[0m \u001b[39m# update momentum_buffers in state\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[39mfor\u001b[39;00m p, momentum_buffer \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001b[1;32mc:\\Users\\hssla\\miniconda3\\Lib\\site-packages\\torch\\optim\\sgd.py:220\u001b[0m, in \u001b[0;36msgd\u001b[1;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_sgd\n\u001b[1;32m--> 220\u001b[0m func(params,\n\u001b[0;32m    221\u001b[0m      d_p_list,\n\u001b[0;32m    222\u001b[0m      momentum_buffer_list,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[0;32m    224\u001b[0m      momentum\u001b[39m=\u001b[39mmomentum,\n\u001b[0;32m    225\u001b[0m      lr\u001b[39m=\u001b[39mlr,\n\u001b[0;32m    226\u001b[0m      dampening\u001b[39m=\u001b[39mdampening,\n\u001b[0;32m    227\u001b[0m      nesterov\u001b[39m=\u001b[39mnesterov,\n\u001b[0;32m    228\u001b[0m      has_sparse_grad\u001b[39m=\u001b[39mhas_sparse_grad,\n\u001b[0;32m    229\u001b[0m      maximize\u001b[39m=\u001b[39mmaximize)\n",
      "File \u001b[1;32mc:\\Users\\hssla\\miniconda3\\Lib\\site-packages\\torch\\optim\\sgd.py:314\u001b[0m, in \u001b[0;36m_multi_tensor_sgd\u001b[1;34m(params, grads, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(device_momentum_buffer_list)):\n\u001b[0;32m    312\u001b[0m     \u001b[39mif\u001b[39;00m device_momentum_buffer_list[i] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m         buf \u001b[39m=\u001b[39m device_momentum_buffer_list[i] \u001b[39m=\u001b[39m momentum_buffer_list[indices[i]] \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> 314\u001b[0m             torch\u001b[39m.\u001b[39mclone(device_grads[i])\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m    315\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m         buf \u001b[39m=\u001b[39m device_momentum_buffer_list[i]\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 11.25 GiB. GPU 0 has a total capacty of 8.00 GiB of which 0 bytes is free. Of the allocated memory 33.81 GiB is allocated by PyTorch, and 705.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Initialize a list to keep track of loss values\n",
    "loss_values = []\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is active.\") \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device (GPU or CPU)\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "\n",
    "        # Move to GPU\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Split the labels\n",
    "        rotation_labels = labels[:, 0]\n",
    "        input_labels = labels[:, 1]\n",
    "\n",
    "        # Reset gradient\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Assuming your model's output is designed to handle both types of labels\n",
    "        loss_rotation = criterion(outputs[0], rotation_labels)\n",
    "        loss_input = criterion(outputs[1], input_labels)\n",
    "        loss = loss_rotation + loss_input  # Combine losses, or handle as you see fit\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # At the end of each epoch, store the average loss\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    loss_values.append(epoch_loss)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct_rotation, correct_input, total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            rotation_labels, input_labels = labels[:, 0], labels[:, 1]\n",
    "\n",
    "            rotation_output, input_output = model(inputs)\n",
    "\n",
    "            _, predicted_rotation = torch.max(rotation_output.data, 1)\n",
    "            _, predicted_input = torch.max(input_output.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct_rotation += (predicted_rotation == rotation_labels).sum().item()\n",
    "            correct_input += (predicted_input == input_labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on rotation prediction: {100 * correct_rotation / total}%')\n",
    "    print(f'Accuracy of the network on input type prediction: {100 * correct_input / total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
