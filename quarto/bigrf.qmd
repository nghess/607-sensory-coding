---
title: "Big Receptive Field"
---

Throughout the project, I wanted to find a way to train a model to learn a convolutional kernel (or collection of kernels) that approximated the sparse-but-uniform structure of orientation-selective cortical columns in MT. As 607 Sensory Coding was about mapping, I was motivated to create a model that "mapped" the entire stimulus space.

Typically, CNNs learn a number of kernel and then cycle through them as they slide across a stimulus. While the results of this process share properties with biological visual systems, there is no structure retinotopic or otherwise, that fixes a particular kernel to a particular location in feature space.

In the course of the project, I had a moment of clarity as to why orientation-selective cortical columns are so nicely interspersed with each other: maximum coverage of the possible feature space. While they are fixed, cortical columns of a particular selectivity span the entire retinotopic map. This coverage is sparser than in a CNN, where every kernel sees every pixel in a stimulus, but the idea is the same.

Based on this thought, I modified my 3DCNN so that the second convolutional layer had a single large kernel that matched the stimulus size exactly. This kernel never moved across the image, rather it sat in place while the stimuli under it changed.

The resulting kernel produced smoothly-transitioning feature detectors, however, I need to reduce the number of channels (dimensions) and train a new model before I can make any comparisons to kernel structure to columns in cortex. 

## Results

![Figure 4: One 16 channel layer of 8 total, each layer shows variations in grain structure.](images/big_rf_grain.png)
